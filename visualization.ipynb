{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This Notebook allow to create and visualize the dataset for this project.\n",
    "\n",
    "Some functions was taked from \"Visión por computadora\" workshop by Mauricio Repetto & Waldemar López \n",
    "\n",
    "(https://drive.google.com/file/d/1neqSeyIqdpufL4EtY6jUirUvWGya0Mkp/view?usp=sharing)\n",
    "\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXr9oRv3A9AM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime; \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from shutil import copy2, rmtree, copytree\n",
    "from tqdm import tqdm\n",
    "from sys import stdout\n",
    "from os import listdir, makedirs, remove\n",
    "from os.path import isfile, join, isdir, exists, dirname, abspath\n",
    "from inspect import getsourcefile\n",
    "from tensorflow import keras\n",
    "from numpy.random import seed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OoR-dXgQjVRm"
   },
   "source": [
    "# Downloading dataset from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EzUBb-HPjVRn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning dataset project from github\n",
      "Cloning into 'dataset'...\n",
      "remote: Enumerating objects: 20, done.\u001b[K\n",
      "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 647 (delta 0), reused 19 (delta 0), pack-reused 627\u001b[K\n",
      "Receiving objects: 100% (647/647), 62.33 MiB | 5.09 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n",
      "Already on 'master'\n",
      "Your branch is up to date with 'origin/master'.\n"
     ]
    }
   ],
   "source": [
    "![ ! -d \"dataset\" ] && echo \"Cloning dataset project from github\" && git clone https://github.com/alphonse92/momo-dataset.git dataset \n",
    "!cd dataset\n",
    "!# Set the dataset branch\n",
    "!git checkout master\n",
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__Gb10ewA9AQ"
   },
   "outputs": [],
   "source": [
    "# Load Inception V3.\n",
    "\n",
    "InceptionV3             = keras.applications.inception_v3.InceptionV3\n",
    "     \n",
    "preprocess_input        = keras.applications.inception_v3.preprocess_input\n",
    "image                   = keras.preprocessing.image\n",
    "     \n",
    "ImageDataGenerator      = keras.preprocessing.image.ImageDataGenerator\n",
    "Callback                = keras.callbacks\n",
    "     \n",
    "Model                   = keras.models.Model\n",
    "Sequential              = keras.models.Sequential\n",
    "layers                  = keras.layers\n",
    "     \n",
    "Input                   = layers.Input\n",
    "Dense                   = layers.Dense\n",
    "Conv2D                  = layers.Conv2D\n",
    "ZeroPadding2D           = layers.ZeroPadding2D\n",
    "BatchNormalization      = layers.BatchNormalization\n",
    "AveragePooling2D        = layers.AveragePooling2D\n",
    "MaxPooling2D            = layers.MaxPooling2D\n",
    "GlobalAveragePooling2D  = layers.GlobalAveragePooling2D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lw7n9uorA9AS"
   },
   "outputs": [],
   "source": [
    "inceptionV3Model = InceptionV3(weights='imagenet', include_top=False, pooling=  'avg')\n",
    "\n",
    "# Uncomment to describe the inception v3 summary model\n",
    "#print(inceptionV3Model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chxHt9JvA9AV"
   },
   "source": [
    "# Notebook Configuration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nKRDESWDA9AV",
    "outputId": "dff9a4df-c699-4f09-ff40-eda37cba2bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Notebook Configuration\n",
    "USE_INCEPTION_V3_MODEL = True\n",
    "RESET_TRAINING_EXAMPLES = True\n",
    "SAVE_WEIGHTS = True\n",
    "SEED_APP = 9\n",
    "\n",
    "# DATASET PROPORTIONS\n",
    "TRAINING_PERCENTAGE = 0.7\n",
    "TESTING_PERCENTAGE  = 0.15\n",
    "EVAL_PERCENTAGE     = 0.15\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "CRITERIA_THRESHOLD = 0.1\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 15\n",
    "IMG_W = IMG_H = 299\n",
    "\n",
    "\n",
    "# MODEL CHECKPOINTS CONFIGURATION\n",
    "SAVE_CHECKPOINTS = 5\n",
    "SAVE_WEIGHTS_FREQUENCY = 'epoch'\n",
    "SAVE_WEIGTHS_PERIOD = EPOCHS // SAVE_CHECKPOINTS\n",
    "\n",
    "# COLAB SCOPE\n",
    "GOOGLE_COLLAB = False                                                            # Default value. You should not modify this\n",
    "GOOGLE_RESET_CONTENT_TREE = True                                                 # Reset the dataset content tree. It means remove and re copy the data from drive\n",
    "MOUNT = \"./\"                                                                     # Base path of this project. You may not change this value   \n",
    "G_MOUNT = \"/content/drive\"                                                       # Set where the drive folder will be mounted\n",
    "G_PROJECT_PATH = G_MOUNT+ \"/My Drive/Colab Notebooks/uruit-ml-momo-test/\"        # Set the pathe where momo project is \n",
    "\n",
    "# If colab instance, then build the content tree\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive', force_remount=GOOGLE_RESET_CONTENT_TREE)\n",
    "  GOOGLE_COLLAB = True\n",
    "except:\n",
    "  GOOGLE_COLLAB = False\n",
    "  print(tf.test.gpu_device_name())\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Pp1IbKlA9AX"
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cLOM_Um3A9AY",
    "outputId": "e26a2d9c-c718-4a56-f7e1-88eda1c988e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/basic/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "tf.random.set_seed(SEED_APP)\n",
    "\n",
    "MOMO_CLASSNAME    = \"momo\"\n",
    "NO_MOMO_CLASSNAME = \"no_momo\"\n",
    "\n",
    "DATASET_PATH = join(MOUNT, \"dataset/\")\n",
    "RESULT_FOLDER_PATH = join(MOUNT,\"result/\")\n",
    "RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH = RESULT_FOLDER_PATH + \"inception_v3/\"\n",
    "DATESET_BASIC_PATH    = join(DATASET_PATH,'basic/')\n",
    "DATESET_TRAINING_PATH = join(DATASET_PATH,'train/')\n",
    "DATESET_TESTING_PATH  = join(DATASET_PATH,'test/')\n",
    "DATESET_EVAL_PATH     = join(DATASET_PATH,'eval/')\n",
    "\n",
    "\n",
    "DEFAULT_WEIGHTS_FILE_PATH = RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights.h5'\n",
    "\n",
    "print(DATESET_BASIC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolders(path):\n",
    "    return [d for d in listdir(path) if isdir(join(path, d))]\n",
    "\n",
    "def getFolderFiles(path: str):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]  \n",
    "\n",
    "\n",
    "def predict(path: str) -> np.array:\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    # Size  (299, 299, 3)\n",
    "    imgArray = image.img_to_array(img) \n",
    "    \n",
    "    # Size  (1, 299, 299, 3)\n",
    "    expandedImgArray = np.expand_dims(imgArray, axis=0) \n",
    "    \n",
    "    # Preproces to inceptionV3, normalize each pixel RGB value to an scale of zero to one\n",
    "    processedImgArray = preprocess_input(expandedImgArray) \n",
    "    \n",
    "    return inceptionV3Model.predict(processedImgArray)\n",
    "\n",
    "def getTimestamp():\n",
    "    return datetime.datetime.now().timestamp()\n",
    "    \n",
    "def getRandomExample(xClass:str):\n",
    "\n",
    "    exampleFileList = getFolderFiles(DATESET_BASIC_PATH + xClass)\n",
    "    \n",
    "    rndIndex = np.random.randint(0,len(exampleFileList))\n",
    "    filename = exampleFileList[rndIndex]\n",
    "    return join(DATESET_BASIC_PATH,xClass,filename)\n",
    "\n",
    "def getClasses():\n",
    "    return getFolders(DATESET_BASIC_PATH)\n",
    "    \n",
    "def createFolderIfNotExist(folderPath):\n",
    "    if not exists(folderPath):\n",
    "        makedirs(folderPath)\n",
    "\n",
    "def deleteIfExist(filepath):\n",
    "    if exists(filepath):\n",
    "        remove(filepath)\n",
    "\n",
    "def saveInFileIfNotExist(filepath: str, content: str):\n",
    "  \n",
    "    # Create (or not) the result folder\n",
    "    createFolderIfNotExist(dirname(filepath))\n",
    "    \n",
    "    with open(filepath, mode=\"a\") as f:\n",
    "        f.write(content + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momo class random file path [[0.7938269  0.08079947 0.2090581  ... 0.76392585 0.5125654  0.18211181]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7938269 , 0.08079947, 0.2090581 , ..., 0.76392585, 0.5125654 ,\n",
       "        0.18211181]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED_APP)\n",
    "\n",
    "CLASSES = getClasses()\n",
    "RANDOM_POSITIVE_EXAMPLE_PATH = getRandomExample(\"momo\")\n",
    "RANDOM_POSITIVE_EXAMPLE_FILE = predict(RANDOM_POSITIVE_EXAMPLE_PATH)\n",
    "print(\"Momo class random file path\" , RANDOM_POSITIVE_EXAMPLE_FILE)\n",
    "\n",
    "predict(RANDOM_POSITIVE_EXAMPLE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CSV to visualize dataset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing meme...\n",
      "100%|██████████| 60/60 [00:05<00:00, 10.92it/s]\n",
      "Processing person...\n",
      "100%|██████████| 88/88 [00:08<00:00, 10.98it/s]\n",
      "Processing momo...\n",
      " 14%|█▎        | 59/435 [00:05<00:37, 10.06it/s]Can't to load:  ./dataset/basic/momo/.DS_Store Please check your dataset and remove it if it is required\n",
      "100%|██████████| 435/435 [00:51<00:00,  8.53it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CSV_PATH = RESULT_FOLDER_PATH + \"basic-predictions/\" + str(getTimestamp()) + \"/result.csv\"\n",
    "\n",
    "# Write in the file the csv Hheaders\n",
    "saveInFileIfNotExist(CSV_PATH, \"class;image_name;predictions\") \n",
    "\n",
    "for _class_ in CLASSES:\n",
    "    classFolderPath = join(DATESET_BASIC_PATH, _class_)\n",
    "    imagePaths = getFolderFiles(classFolderPath)\n",
    "    \n",
    "    print(f\"Processing {_class_}...\")\n",
    "    \n",
    "    for imgName in tqdm(imagePaths, file=stdout):\n",
    "        imagePath = join(classFolderPath, imgName)\n",
    "        # Inception V3 return an array of (1,2048)\n",
    "        try:\n",
    "            predictions = predict(imagePath)\n",
    "\n",
    "            # Get a CSV row for the current class,image and prediction\n",
    "            csvRow = f'\"{_class_}\";\"{imgName}\";\"{\",\".join([ str(pred) for pred in predictions[0]])}\"'\n",
    "            saveInFileIfNotExist(CSV_PATH, csvRow)\n",
    "        except Exception:\n",
    "            print(\"Can't to load: \" , imagePath, \"Please check your dataset and remove it if it is required\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading csv:\" ,CSV_PATH)\n",
    "\n",
    "# Create dataframe with pandas\n",
    "df = pd.read_csv(CSV_PATH, sep=';')\n",
    "\n",
    "# Check the head\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions as float\n",
    "df['predictions_float'] = df['predictions'].apply(lambda x: np.array([float(str_dim) for str_dim in x.split(',')], dtype=np.float32))\n",
    "\n",
    "# Save as np array the predictions per record\n",
    "vectors = np.array(df['predictions_float'].tolist())\n",
    "\n",
    "# Print the size (m,2048) where m is the length of our dataset. and 2048 is the predictions\n",
    "# For each class in inception\n",
    "print(\"vectors\" , vectors.shape)\n",
    "\n",
    "folderResults       = dirname(CSV_PATH)\n",
    "filenameTsvLabels   = folderResults + \"/\" + \"result_labels.tsv\" \n",
    "filenameTsvEmbdings = folderResults + \"/\" + \"result_embdings.tsv\" \n",
    "\n",
    "deleteIfExist(filenameTsvLabels)\n",
    "deleteIfExist(filenameTsvEmbdings)\n",
    "\n",
    "with open(filenameTsvLabels,'w') as f:\n",
    "    f.write(\"Index\\tLabel\\n\")\n",
    "    for index,(file, label) in enumerate(zip(df.image_name, df[\"class\"])):\n",
    "        f.write(f'{label} - {file}\\t{label}\\n')\n",
    "\n",
    "        \n",
    "with open(filenameTsvEmbdings,'w') as f:\n",
    "    for dims in vectors:\n",
    "        f.write('\\t'.join([str(dim) for dim in dims])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data using tensorflow embding projection\n",
    "\n",
    "This tool allow to users to visualize him data. Use the last folder in result/basic-predictions/\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Click on Load buttom\n",
    "2. In step 1 select the file `result_embdings.tsv`\n",
    "3. In step 2 select the file `result_labels.tsv`\n",
    "4. Click outside the modal\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "![screenshot using tf embding projector](./docs/tensorflowEmbdingProjector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 2 dimension Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data before\n",
    "vectors_std = StandardScaler().fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_std[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(vectors_std)\n",
    "print(principalComponents.shape)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting using matplot lib\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "\n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "targets = getClasses()\n",
    "colors = ['r', 'g', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = df['class'] == target    \n",
    "    ax.scatter(principalComponents[indicesToKeep][:,0:1]\n",
    "               , principalComponents[indicesToKeep][:,1:2]\n",
    "               , c = color\n",
    "               , s = 10)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
