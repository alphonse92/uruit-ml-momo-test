{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook show the performance analisys on our model\n",
    "\n",
    "# Requeriments\n",
    "\n",
    "Do the training notebook first this to generate the weights if you have not it yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime; \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from shutil import copy2, rmtree\n",
    "from tqdm import tqdm\n",
    "from sys import stdout\n",
    "from os import listdir, makedirs, remove\n",
    "from os.path import isfile, join, isdir, exists, dirname\n",
    "from tensorflow import keras\n",
    "from numpy.random import seed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Project modules below\n",
    "from lib import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Inception V3.\n",
    "\n",
    "InceptionV3        = keras.applications.inception_v3.InceptionV3\n",
    "preprocess_input   = keras.applications.inception_v3.preprocess_input\n",
    "image              = keras.preprocessing.image\n",
    "Model              = keras.models.Model\n",
    "Dense              = keras.layers.Dense\n",
    "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3Model = InceptionV3(weights='imagenet', include_top=False, pooling=  'avg')\n",
    "# Uncomment to describe the inception v3 summary model\n",
    "#print(inceptionV3Model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/basic/\n"
     ]
    }
   ],
   "source": [
    "SEED_APP = 123\n",
    "SAVE_WEIGHTS = True\n",
    "EPOCHS = 10\n",
    "tf.random.set_seed(SEED_APP)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "IMG_W = IMG_H = 299\n",
    "\n",
    "MOMO_CLASSNAME    = \"momo\"\n",
    "NO_MOMO_CLASSNAME = \"no_momo\"\n",
    "\n",
    "MOUNT = \"./\"\n",
    "DATASET_PATH = join(MOUNT, \"dataset/\")\n",
    "RESULT_FOLDER_PATH = join(MOUNT,\"result/\")\n",
    "RESULT_WEIGHTS_PATH = RESULT_FOLDER_PATH + \"weights.h5\"\n",
    "\n",
    "DATESET_BASIC_PATH    = join(DATASET_PATH,'basic/')\n",
    "DATESET_TRAINING_PATH = join(DATASET_PATH,'train/')\n",
    "DATESET_TESTING_PATH  = join(DATASET_PATH,'test/')\n",
    "DATESET_EVAL_PATH     = join(DATASET_PATH,'eval/')\n",
    "\n",
    "print(DATESET_BASIC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolders(path):\n",
    "    return [d for d in listdir(path) if isdir(join(path, d))]\n",
    "\n",
    "def getFolderFiles(path: str):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]  \n",
    "\n",
    "\n",
    "def predict(path: str, model=inceptionV3Model) -> np.array:\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    # Size  (299, 299, 3)\n",
    "    imgArray = image.img_to_array(img) \n",
    "    \n",
    "    # Size  (1, 299, 299, 3)\n",
    "    expandedImgArray = np.expand_dims(imgArray, axis=0) \n",
    "    \n",
    "    # Preproces to inceptionV3, normalize each pixel RGB value to an scale of zero to one\n",
    "    processedImgArray = preprocess_input(expandedImgArray) \n",
    "    \n",
    "    return model.predict(processedImgArray)\n",
    "\n",
    "def getTimestamp():\n",
    "    return datetime.datetime.now().timestamp()\n",
    "    \n",
    "def getRandomExample(xClass:str):\n",
    "\n",
    "    exampleFileList = getFolderFiles(DATESET_BASIC_PATH + xClass)\n",
    "    \n",
    "    rndIndex = np.random.randint(0,len(exampleFileList))\n",
    "    filename = exampleFileList[rndIndex]\n",
    "    return join(DATESET_BASIC_PATH,xClass,filename)\n",
    "\n",
    "def getDatasetClasses():\n",
    "    return getFolders(DATESET_BASIC_PATH)\n",
    "\n",
    "def getOutputClasses():\n",
    "    return [NO_MOMO_CLASSNAME,MOMO_CLASSNAME]\n",
    "    \n",
    "def createFolderIfNotExist(folderPath):\n",
    "    if not exists(folderPath):\n",
    "        makedirs(folderPath)\n",
    "\n",
    "def deleteIfExist(filepath):\n",
    "    if exists(filepath):\n",
    "        rmtree(filepath)\n",
    "        \n",
    "def resetFolderIfExist(path : str):\n",
    "    deleteIfExist(path)\n",
    "    createFolderIfNotExist(path)\n",
    "\n",
    "def saveInFileIfNotExist(filepath: str, content: str):\n",
    "  \n",
    "    # Create (or not) the result folder\n",
    "    createFolderIfNotExist(dirname(filepath))\n",
    "    \n",
    "    with open(filepath, mode=\"a\") as f:\n",
    "        f.write(content + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing InceptionV3 Model to fit it to our problem: identify momo in. images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the output of the model\n",
    "x = inceptionV3Model.output\n",
    "\n",
    "# Add a full-conected layer of 1024 neurons with relu activation to our model output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a output layer with only one neurone\n",
    "momoOutput = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the momo Model from our outputs\n",
    "momoModel = Model(inputs=inceptionV3Model.input, outputs=momoOutput)\n",
    "\n",
    "# Compile our model using adam and an optimizer for binari clasification\n",
    "momoModel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(momoModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights on our model\n",
    "momoModel.load_weights(RESULT_WEIGHTS_PATH)\n",
    "momoModel.output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Using the momo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing no_momo  total of images:  21\n",
      "100%|██████████| 21/21 [00:01<00:00, 11.24it/s]\n",
      "Processing momo  total of images:  16\n",
      "100%|██████████| 16/16 [00:01<00:00, 12.75it/s]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "eval_Xs = []\n",
    "eval_Ys = []\n",
    "eval_preds = []\n",
    "files = []\n",
    "\n",
    "folders = getFolders(DATESET_EVAL_PATH)\n",
    "\n",
    "for folder in folders:\n",
    "    \n",
    "    images                = getFolderFiles(DATESET_EVAL_PATH+ folder)\n",
    "    totalOfImagesInFolder = len(images)\n",
    "    \n",
    "    print(\"Processing\" ,  folder , \" total of images: \",totalOfImagesInFolder)\n",
    "    \n",
    "    for img in tqdm(images, file=stdout):\n",
    "        src = DATESET_EVAL_PATH + folder + \"/\" + img        \n",
    "        files.append(src)\n",
    "        result = predict(src,momoModel)[0][0]\n",
    "        \n",
    "        # generamos una lista con las probabilidades devueltas por el modelo para cada imagen.\n",
    "        eval_preds.append(result)\n",
    "        \n",
    "        # generamos nuestra lista de y_true, es decir la etiqueta de quebería tener la foto.\n",
    "        eval_Xs.append(1 if folder == \"momo\" else 0)\n",
    "        \n",
    "        # generamos nuestra lista de y_pred, es decir la etiqueta que nos dio la predicción.\n",
    "        eval_Ys.append(1 if result > threshold else 0)\n",
    "\n",
    "files      = np.array(files)\n",
    "eval_preds = np.array(eval_preds)\n",
    "eval_Xs    = np.array(eval_Xs)\n",
    "eval_Ys    = np.array(eval_Ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
