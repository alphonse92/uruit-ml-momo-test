{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebooks prepare our dataset before the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime; \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from shutil import copy2, rmtree\n",
    "from tqdm import tqdm\n",
    "from sys import stdout\n",
    "from os import listdir, makedirs, remove\n",
    "from os.path import isfile, join, isdir, exists, dirname\n",
    "from tensorflow import keras\n",
    "from numpy.random import seed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Project modules below\n",
    "from lib import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Inception V3.\n",
    "\n",
    "InceptionV3        = keras.applications.inception_v3.InceptionV3\n",
    "preprocess_input   = keras.applications.inception_v3.preprocess_input\n",
    "image              = keras.preprocessing.image\n",
    "Model              = keras.models.Model\n",
    "Dense              = keras.layers.Dense\n",
    "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3Model = InceptionV3(weights='imagenet', include_top=False, pooling=  'avg')\n",
    "# Uncomment to describe the inception v3 summary model\n",
    "#print(inceptionV3Model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/basic/\n"
     ]
    }
   ],
   "source": [
    "SEED_APP = 123\n",
    "tf.random.set_seed(SEED_APP)\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "IMG_W = IMG_H = 299\n",
    "\n",
    "MOMO_CLASSNAME    = \"momo\"\n",
    "NO_MOMO_CLASSNAME = \"no_momo\"\n",
    "\n",
    "MOUNT = \"./\"\n",
    "DATASET_PATH = join(MOUNT, \"dataset/\")\n",
    "RESULT_FOLDER_PATH = join(MOUNT,\"result/\")\n",
    "\n",
    "DATESET_BASIC_PATH    = join(DATASET_PATH,'basic/')\n",
    "DATESET_TRAINING_PATH = join(DATASET_PATH,'train/')\n",
    "DATESET_TESTING_PATH  = join(DATASET_PATH,'test/')\n",
    "DATESET_EVAL_PATH     = join(DATASET_PATH,'eval/')\n",
    "\n",
    "print(DATESET_BASIC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolders(path):\n",
    "    return [d for d in listdir(path) if isdir(join(path, d))]\n",
    "\n",
    "def getFolderFiles(path: str):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]  \n",
    "\n",
    "\n",
    "def predict(path: str) -> np.array:\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    # Size  (299, 299, 3)\n",
    "    imgArray = image.img_to_array(img) \n",
    "    \n",
    "    # Size  (1, 299, 299, 3)\n",
    "    expandedImgArray = np.expand_dims(imgArray, axis=0) \n",
    "    \n",
    "    # Preproces to inceptionV3, normalize each pixel RGB value to an scale of zero to one\n",
    "    processedImgArray = preprocess_input(expandedImgArray) \n",
    "    \n",
    "    return inceptionV3Model.predict(processedImgArray)\n",
    "\n",
    "def getTimestamp():\n",
    "    return datetime.datetime.now().timestamp()\n",
    "    \n",
    "def getRandomExample(xClass:str):\n",
    "\n",
    "    exampleFileList = getFolderFiles(DATESET_BASIC_PATH + xClass)\n",
    "    \n",
    "    rndIndex = np.random.randint(0,len(exampleFileList))\n",
    "    filename = exampleFileList[rndIndex]\n",
    "    return join(DATESET_BASIC_PATH,xClass,filename)\n",
    "\n",
    "def getDatasetClasses():\n",
    "    return getFolders(DATESET_BASIC_PATH)\n",
    "\n",
    "def getOutputClasses():\n",
    "    return [MOMO_CLASSNAME,NO_MOMO_CLASSNAME]\n",
    "    \n",
    "def createFolderIfNotExist(folderPath):\n",
    "    if not exists(folderPath):\n",
    "        makedirs(folderPath)\n",
    "\n",
    "def deleteIfExist(filepath):\n",
    "    if exists(filepath):\n",
    "        rmtree(filepath)\n",
    "        \n",
    "def resetFolderIfExist(path : str):\n",
    "    deleteIfExist(path)\n",
    "    createFolderIfNotExist(path)\n",
    "\n",
    "def saveInFileIfNotExist(filepath: str, content: str):\n",
    "  \n",
    "    # Create (or not) the result folder\n",
    "    createFolderIfNotExist(dirname(filepath))\n",
    "    \n",
    "    with open(filepath, mode=\"a\") as f:\n",
    "        f.write(content + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momo class random file path [[0.19734913 0.45167    0.06192229 ... 0.13883413 0.17555334 0.6870728 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19734913, 0.45167   , 0.06192229, ..., 0.13883413, 0.17555334,\n",
       "        0.6870728 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(SEED_APP)\n",
    "\n",
    "CLASSES = getDatasetClasses()\n",
    "RANDOM_POSITIVE_EXAMPLE_PATH = getRandomExample(\"momo\")\n",
    "RANDOM_POSITIVE_EXAMPLE_FILE = predict(RANDOM_POSITIVE_EXAMPLE_PATH)\n",
    "print(\"Momo class random file path\" , RANDOM_POSITIVE_EXAMPLE_FILE)\n",
    "\n",
    "predict(RANDOM_POSITIVE_EXAMPLE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing InceptionV3 Model to adjust it to our problem: identify momo in. images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the output of the model\n",
    "x = inceptionV3Model.output\n",
    "\n",
    "# Add a full-conected layer of 1024 neurons with relu activation to our model output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a output layer with only one neurone\n",
    "momoOutput = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the momo Model from our outputs\n",
    "momoModel = Model(inputs=inceptionV3Model.input, outputs=momoOutput)\n",
    "\n",
    "# Compile our model using adam and an optimizer for binari clasification\n",
    "momoModel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(momoModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our test/training folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each class of the dataset\n",
    "for ds_class in getOutputClasses():\n",
    "    # Create the folders in the train/test folders\n",
    "    resetFolderIfExist( DATESET_TRAINING_PATH  +  ds_class  )\n",
    "    resetFolderIfExist( DATESET_TESTING_PATH   +  ds_class  )\n",
    "    resetFolderIfExist( DATESET_EVAL_PATH      +  ds_class  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the train/test/eval folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From folder 'meme' take 42 Training examples, 9 Testing examples, and 9 Eval examples.\n",
      "Copying traning files from ./dataset/basic/meme to ./dataset/train/no_momo\n",
      "100%|██████████| 42/42 [00:00<00:00, 1699.92it/s]\n",
      "Copying testing files from ./dataset/basic/meme to ./dataset/test/no_momo\n",
      "100%|██████████| 9/9 [00:00<00:00, 1339.65it/s]\n",
      "Copying eval files from ./dataset/basic/meme to ./dataset/eval/no_momo\n",
      "100%|██████████| 9/9 [00:00<00:00, 1037.94it/s]\n",
      "From folder 'person' take 62 Training examples, 14 Testing examples, and 12 Eval examples.\n",
      "Copying traning files from ./dataset/basic/person to ./dataset/train/no_momo\n",
      "100%|██████████| 62/62 [00:00<00:00, 1159.62it/s]\n",
      "Copying testing files from ./dataset/basic/person to ./dataset/test/no_momo\n",
      "100%|██████████| 14/14 [00:00<00:00, 1661.72it/s]\n",
      "Copying eval files from ./dataset/basic/person to ./dataset/eval/no_momo\n",
      "100%|██████████| 12/12 [00:00<00:00, 1784.87it/s]\n",
      "From folder 'momo' take 80 Training examples, 17 Testing examples, and 16 Eval examples.\n",
      "Copying traning files from ./dataset/basic/momo to ./dataset/train/momo\n",
      "100%|██████████| 80/80 [00:00<00:00, 2026.03it/s]\n",
      "Copying testing files from ./dataset/basic/momo to ./dataset/test/momo\n",
      "100%|██████████| 17/17 [00:00<00:00, 2068.38it/s]\n",
      "Copying eval files from ./dataset/basic/momo to ./dataset/eval/momo\n",
      "100%|██████████| 16/16 [00:00<00:00, 1775.60it/s]\n"
     ]
    }
   ],
   "source": [
    "DATASET_CLASSES = getDatasetClasses()\n",
    "\n",
    "\n",
    "# Proportions\n",
    "TRAINING_PERCENTAGE = 0.7\n",
    "TESTING_PERCENTAGE  = 0.15\n",
    "EVAL_PERCENTAGE     = 0.15\n",
    "\n",
    "ds_folders = getFolders(DATESET_BASIC_PATH)\n",
    "\n",
    "for ds_folder in ds_folders:\n",
    "    \n",
    "    path      = DATESET_BASIC_PATH + ds_folder\n",
    "    files     = np.array(getFolderFiles(path))\n",
    "\n",
    "    m         = len(files)\n",
    "    \n",
    "    trainIdx  = math.ceil( m * TRAINING_PERCENTAGE )\n",
    "    testIdx   = math.ceil( m * TESTING_PERCENTAGE  ) \n",
    "    evalIdx   = math.ceil( m * EVAL_PERCENTAGE     )     \n",
    "    \n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    isPositiveClass      = ds_folder == MOMO_CLASSNAME\n",
    "    folderTo             = MOMO_CLASSNAME if isPositiveClass else NO_MOMO_CLASSNAME\n",
    "    \n",
    "    trainingClassPath    = DATESET_TRAINING_PATH + folderTo\n",
    "    testClassPath        = DATESET_TESTING_PATH  + folderTo\n",
    "    evalClassPath        = DATESET_EVAL_PATH     + folderTo\n",
    "    \n",
    "   \n",
    "    currentIndex     = 0\n",
    "    trainingImages   = files[ currentIndex : currentIndex + trainIdx ]\n",
    "    \n",
    "    currentIndex     = currentIndex + trainIdx \n",
    "    testImages       = files[ currentIndex : currentIndex + testIdx  ]\n",
    "    \n",
    "    currentIndex     = currentIndex + testIdx\n",
    "    evalImages       = files[ currentIndex :          ]\n",
    "    \n",
    "    print(\n",
    "        \"From folder '\" + ds_folder  + \"'\"\n",
    "        + \" take \" \n",
    "        + str(len(trainingImages)) + \" Training examples, \"\n",
    "        + str(len(testImages))     + \" Testing examples, and \"\n",
    "        + str(len(evalImages))     + \" Eval examples.\"        \n",
    "    )\n",
    "    \n",
    "    print(\"Copying traning files from \" + path + \" to \" + trainingClassPath)\n",
    "    for imageName in tqdm(trainingImages, file=stdout):\n",
    "        copy2(path+ \"/\"+  imageName ,trainingClassPath + \"/\"+  imageName)\n",
    "        \n",
    "    print(\"Copying testing files from \" + path + \" to \" + testClassPath)\n",
    "    for imageName in tqdm(testImages, file=stdout):\n",
    "        copy2(path+ \"/\"+  imageName ,testClassPath + \"/\"+  imageName)\n",
    "        \n",
    "    print(\"Copying eval files from \"    + path + \" to \" + evalClassPath)\n",
    "    for imageName in tqdm(evalImages, file=stdout):\n",
    "        copy2(path+ \"/\"+  imageName ,evalClassPath + \"/\"+  imageName)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator to pre process our dataset images\n",
    "imageGenerator = ImageDataGenerator(\n",
    "    rescale          = 1./255,       # Scale our data to our dataset scale\n",
    "    horizontal_flip  = True, # Horizontal mirror\n",
    "    vertical_flip    = False   # Disable vertical mirror\n",
    ")\n",
    "\n",
    "trainGenerator = imageGenerator.flow_from_directory(\n",
    "        directory   = DATESET_BASIC_PATH + \"momo\",\n",
    "        target_size =  (IMG_H, IMG_W),\n",
    "        batch_size  =  BATCH_SIZE,\n",
    "        class_mode  =  'binary',\n",
    "        classes     =  getOutputClasses())\n",
    "\n",
    "testGenerator= imageGenerator.flow_from_directory(\n",
    "        directory    = DATESET_BASIC_PATH + \"momo\",\n",
    "        target_size  = (IMG_H, IMG_W),\n",
    "        batch_size   = BATCH_SIZE,\n",
    "        class_mode   = 'binary',\n",
    "        classes      = getOutputClasses())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
