{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook shows how to create a new custom neural network model to detect momo in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime; \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from shutil import copy2, rmtree\n",
    "from tqdm import tqdm\n",
    "from sys import stdout\n",
    "from os import listdir, makedirs, remove\n",
    "from os.path import isfile, join, isdir, exists, dirname\n",
    "from tensorflow import keras\n",
    "from numpy.random import seed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Project modules below\n",
    "from lib import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Inception V3.\n",
    "\n",
    "InceptionV3        = keras.applications.inception_v3.InceptionV3\n",
    "preprocess_input   = keras.applications.inception_v3.preprocess_input\n",
    "image              = keras.preprocessing.image\n",
    "Model              = keras.models.Model\n",
    "Sequential         = keras.models.Sequential\n",
    "Dense              = keras.layers.Dense\n",
    "ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator\n",
    "Callback           = keras.callbacks\n",
    "\n",
    "datasets           = keras.datasets\n",
    "layers             = keras.layers\n",
    "models             = keras.models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3Model = InceptionV3(weights='imagenet', include_top=False, pooling=  'avg')\n",
    "\n",
    "# Uncomment to describe the inception v3 summary model\n",
    "#print(inceptionV3Model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change this value if you want to change the randomic data\n",
    "SEED_APP = 9\n",
    "SAVE_WEIGHTS = True\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 10\n",
    "IMG_W = IMG_H = INPUT_SIZE = 299\n",
    "RESET_TRAINING_EXAMPLES = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/basic/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(SEED_APP)\n",
    "\n",
    "MOMO_CLASSNAME    = \"momo\"\n",
    "NO_MOMO_CLASSNAME = \"no_momo\"\n",
    "\n",
    "MOUNT = \"./\"\n",
    "DATASET_PATH = join(MOUNT, \"dataset/\")\n",
    "RESULT_FOLDER_PATH = join(MOUNT,\"result/\")\n",
    "RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH = RESULT_FOLDER_PATH + \"custom-v1/\"\n",
    "DATESET_BASIC_PATH    = join(DATASET_PATH,'basic/')\n",
    "DATESET_TRAINING_PATH = join(DATASET_PATH,'train/')\n",
    "DATESET_TESTING_PATH  = join(DATASET_PATH,'test/')\n",
    "DATESET_EVAL_PATH     = join(DATASET_PATH,'eval/')\n",
    "\n",
    "\n",
    "DEFAULT_WEIGHTS_FILE_PATH = RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights.h5'\n",
    "\n",
    "print(DATESET_BASIC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFolders(path):\n",
    "    return [d for d in listdir(path) if isdir(join(path, d))]\n",
    "\n",
    "def getFolderFiles(path: str):\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]  \n",
    "\n",
    "\n",
    "def predict(path: str, model=inceptionV3Model) -> np.array:\n",
    "    img = image.load_img(path, target_size=(299, 299))\n",
    "    # Size  (299, 299, 3)\n",
    "    imgArray = image.img_to_array(img) \n",
    "    \n",
    "    # Size  (1, 299, 299, 3)\n",
    "    expandedImgArray = np.expand_dims(imgArray, axis=0) \n",
    "    \n",
    "    # Preproces to inceptionV3, normalize each pixel RGB value to an scale of zero to one\n",
    "    processedImgArray = preprocess_input(expandedImgArray) \n",
    "    \n",
    "    return model.predict(processedImgArray)\n",
    "\n",
    "def getTimestamp():\n",
    "    return datetime.datetime.now().timestamp()\n",
    "    \n",
    "def getRandomExample(xClass:str):\n",
    "    np.random.seed(SEED_APP)\n",
    "    exampleFileList = getFolderFiles(DATESET_BASIC_PATH + xClass)\n",
    "    \n",
    "    rndIndex = np.random.randint(0,len(exampleFileList))\n",
    "    filename = exampleFileList[rndIndex]\n",
    "    return join(DATESET_BASIC_PATH,xClass,filename)\n",
    "\n",
    "def getDatasetClasses():\n",
    "    return getFolders(DATESET_BASIC_PATH)\n",
    "\n",
    "def getOutputClasses():\n",
    "    return [NO_MOMO_CLASSNAME,MOMO_CLASSNAME]\n",
    "    \n",
    "def createFolderIfNotExist(folderPath):\n",
    "    if not exists(folderPath):\n",
    "        makedirs(folderPath)\n",
    "\n",
    "def deleteIfExist(filepath):\n",
    "    if exists(filepath):\n",
    "        rmtree(filepath)\n",
    "        \n",
    "def resetFolderIfExist(path : str):\n",
    "    deleteIfExist(path)\n",
    "    createFolderIfNotExist(path)\n",
    "\n",
    "def saveInFileIfNotExist(filepath: str, content: str):\n",
    "  \n",
    "    # Create (or not) the result folder\n",
    "    createFolderIfNotExist(dirname(filepath))\n",
    "    \n",
    "    with open(filepath, mode=\"a\") as f:\n",
    "        f.write(content + '\\n')\n",
    "        \n",
    "\n",
    "def createConfusionMatrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]                \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    print()\n",
    "    \n",
    "def getDataForConfusionMatrix(useWeights:str =  DEFAULT_WEIGHTS_FILE_PATH ):\n",
    "    \n",
    "    momoModel.load_weights(useWeights)\n",
    "    \n",
    "    threshold = 0.1\n",
    "    eval_Xs = []\n",
    "    eval_Ys = []\n",
    "    eval_preds = []\n",
    "    files = []\n",
    "\n",
    "    #folderPath = DATESET_TRAINING_PATH\n",
    "    folderPath = DATESET_EVAL_PATH\n",
    "\n",
    "    folders = getFolders(folderPath)\n",
    "\n",
    "    for folder in folders:\n",
    "\n",
    "        images                = getFolderFiles(folderPath+ folder)\n",
    "        totalOfImagesInFolder = len(images)\n",
    "\n",
    "        print(\"Processing\" ,  folder , \" total of images: \",totalOfImagesInFolder)\n",
    "\n",
    "        for img in tqdm(images, file=stdout):\n",
    "            src = folderPath + folder + \"/\" + img        \n",
    "            files.append(src)\n",
    "            result = predict(src,momoModel)[0][0]\n",
    "\n",
    "            # generamos una lista con las probabilidades devueltas por el modelo para cada imagen.\n",
    "            eval_preds.append(result)\n",
    "\n",
    "            # generamos nuestra lista de y_true, es decir la etiqueta de quebería tener la foto.\n",
    "            eval_Xs.append(1 if folder == MOMO_CLASSNAME else 0)\n",
    "\n",
    "            # generamos nuestra lista de y_pred, es decir la etiqueta que nos dio la predicción.\n",
    "            eval_Ys.append(1 if result > threshold else 0)\n",
    "\n",
    "    files      = np.array(files)\n",
    "    eval_preds = np.array(eval_preds)\n",
    "    eval_Xs    = np.array(eval_Xs)\n",
    "    eval_Ys    = np.array(eval_Ys)\n",
    "    \n",
    "    momoModel.load_weights(DEFAULT_WEIGHTS_FILE_PATH)\n",
    "    return (files,eval_preds,eval_Xs,eval_Ys)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Input(( None, None , 3)                , name=\"Input\"        ))\n",
    "model.add(layers.ZeroPadding2D((3, 3)                   , name=\"Zero_padding\" ))\n",
    "  \n",
    "model.add(layers.Conv2D(32, (3,3),  activation='relu'    , name=\"cnn2d_1\"      ))\n",
    "model.add(layers.BatchNormalization( axis=3              , name=\"bn_1\"   ))\n",
    "model.add(layers.AveragePooling2D((3, 3)                 , name=\"max_pool_1\"   ))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'   , name=\"cnn2d_2\"      ))\n",
    "model.add(layers.BatchNormalization( axis=3              , name=\"bn_2\"   ))\n",
    "model.add(layers.MaxPooling2D((3, 3)                    , name=\"max_pool_2\"   ))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'   , name=\"cnn2d_3\"      ))\n",
    "model.add(layers.BatchNormalization( axis=3              , name=\"bn_3\"   ))\n",
    "model.add(layers.MaxPooling2D((3, 3)                    , name=\"max_pool_3\"   ))\n",
    "\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'   , name=\"cnn2d_4\"      ))\n",
    "model.add(layers.BatchNormalization( axis=3              , name=\"bn_4\"   ))\n",
    "model.add(layers.MaxPooling2D((3, 3)                    , name=\"max_pool_4\"   ))\n",
    "   \n",
    "#model.add(layers.Conv2D(256, (3, 3), activation='relu'  , name=\"cnn2d_3\"      ))\n",
    "#model.add(layers.MaxPooling2D((3, 3)                    , name=\"max_pool_3\"   ))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(64, activation='relu'            , name=\"fully_1\"))\n",
    "model.add(layers.Dense(1,  activation='sigmoid'         , name=\"output\"))\n",
    "\n",
    "# Compile our model using adam and an optimizer for binari clasification\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "momoModel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Zero_padding (ZeroPadding2D) (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "cnn2d_1 (Conv2D)             (None, None, None, 32)    896       \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pool_1 (AveragePooling2D (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "cnn2d_2 (Conv2D)             (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "bn_2 (BatchNormalization)    (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)    (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "cnn2d_3 (Conv2D)             (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "bn_3 (BatchNormalization)    (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "max_pool_3 (MaxPooling2D)    (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "cnn2d_4 (Conv2D)             (None, None, None, 512)   590336    \n",
      "_________________________________________________________________\n",
      "bn_4 (BatchNormalization)    (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "max_pool_4 (MaxPooling2D)    (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fully_1 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 719,425\n",
      "Trainable params: 717,953\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(momoModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our test/training folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each class of the dataset\n",
    "for ds_class in getOutputClasses():\n",
    "    # Create the folders in the train/test folders\n",
    "    resetFolderIfExist( DATESET_TRAINING_PATH  +  ds_class  )\n",
    "    resetFolderIfExist( DATESET_TESTING_PATH   +  ds_class  )\n",
    "    resetFolderIfExist( DATESET_EVAL_PATH      +  ds_class  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the train/test/eval folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From folder 'meme' take 42 Training examples, 9 Testing examples, and 9 Eval examples.\n",
      "Copying traning files from ./dataset/basic/meme to ./dataset/train/no_momo\n",
      "100%|██████████| 42/42 [00:00<00:00, 794.31it/s]\n",
      "Copying testing files from ./dataset/basic/meme to ./dataset/test/no_momo\n",
      "100%|██████████| 9/9 [00:00<00:00, 968.56it/s]\n",
      "Copying eval files from ./dataset/basic/meme to ./dataset/eval/no_momo\n",
      "100%|██████████| 9/9 [00:00<00:00, 1080.17it/s]\n",
      "From folder 'person' take 62 Training examples, 14 Testing examples, and 12 Eval examples.\n",
      "Copying traning files from ./dataset/basic/person to ./dataset/train/no_momo\n",
      "100%|██████████| 62/62 [00:00<00:00, 755.64it/s]\n",
      "Copying testing files from ./dataset/basic/person to ./dataset/test/no_momo\n",
      "100%|██████████| 14/14 [00:00<00:00, 720.65it/s]\n",
      "Copying eval files from ./dataset/basic/person to ./dataset/eval/no_momo\n",
      "100%|██████████| 12/12 [00:00<00:00, 1109.36it/s]\n",
      "From folder 'momo' take 80 Training examples, 17 Testing examples, and 16 Eval examples.\n",
      "Copying traning files from ./dataset/basic/momo to ./dataset/train/momo\n",
      "100%|██████████| 80/80 [00:00<00:00, 997.23it/s]\n",
      "Copying testing files from ./dataset/basic/momo to ./dataset/test/momo\n",
      "100%|██████████| 17/17 [00:00<00:00, 956.19it/s]\n",
      "Copying eval files from ./dataset/basic/momo to ./dataset/eval/momo\n",
      "100%|██████████| 16/16 [00:00<00:00, 1223.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def CreateTrainTestAndEvalFolders():\n",
    "    np.random.seed(SEED_APP)\n",
    "    DATASET_CLASSES = getDatasetClasses()\n",
    "\n",
    "    # Proportions\n",
    "    TRAINING_PERCENTAGE = 0.7\n",
    "    TESTING_PERCENTAGE  = 0.15\n",
    "    EVAL_PERCENTAGE     = 0.15\n",
    "\n",
    "    ds_folders = getFolders(DATESET_BASIC_PATH)\n",
    "\n",
    "    for ds_folder in ds_folders:\n",
    "\n",
    "        path      = DATESET_BASIC_PATH + ds_folder\n",
    "        files     = np.array(getFolderFiles(path))\n",
    "\n",
    "        m         = len(files)\n",
    "\n",
    "        trainIdx  = math.ceil( m * TRAINING_PERCENTAGE )\n",
    "        testIdx   = math.ceil( m * TESTING_PERCENTAGE  ) \n",
    "        evalIdx   = math.ceil( m * EVAL_PERCENTAGE     )     \n",
    "\n",
    "        np.random.shuffle(files)\n",
    "\n",
    "        isPositiveClass      = ds_folder == MOMO_CLASSNAME\n",
    "        folderTo             = MOMO_CLASSNAME if isPositiveClass else NO_MOMO_CLASSNAME\n",
    "\n",
    "        trainingClassPath    = DATESET_TRAINING_PATH + folderTo\n",
    "        testClassPath        = DATESET_TESTING_PATH  + folderTo\n",
    "        evalClassPath        = DATESET_EVAL_PATH     + folderTo\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        currentIndex     = 0\n",
    "        trainingImages   = files[ currentIndex : currentIndex + trainIdx ]\n",
    "\n",
    "        currentIndex     = currentIndex + trainIdx \n",
    "        testImages       = files[ currentIndex : currentIndex + testIdx  ]\n",
    "\n",
    "        currentIndex     = currentIndex + testIdx\n",
    "        evalImages       = files[ currentIndex :          ]\n",
    "\n",
    "        print(\n",
    "            \"From folder '\" + ds_folder  + \"'\"\n",
    "            + \" take \" \n",
    "            + str(len(trainingImages)) + \" Training examples, \"\n",
    "            + str(len(testImages))     + \" Testing examples, and \"\n",
    "            + str(len(evalImages))     + \" Eval examples.\"        \n",
    "        )\n",
    "\n",
    "        print(\"Copying traning files from \" + path + \" to \" + trainingClassPath)\n",
    "        for imageName in tqdm(trainingImages, file=stdout):\n",
    "            copy2(path+ \"/\"+  imageName ,trainingClassPath + \"/\"+  imageName)\n",
    "\n",
    "        print(\"Copying testing files from \" + path + \" to \" + testClassPath)\n",
    "        for imageName in tqdm(testImages, file=stdout):\n",
    "            copy2(path+ \"/\"+  imageName ,testClassPath + \"/\"+  imageName)\n",
    "\n",
    "        print(\"Copying eval files from \"    + path + \" to \" + evalClassPath)\n",
    "        for imageName in tqdm(evalImages, file=stdout):\n",
    "            copy2(path+ \"/\"+  imageName ,evalClassPath + \"/\"+  imageName)\n",
    "            \n",
    "CreateTrainTestAndEvalFolders()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 184 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator to pre process our dataset images\n",
    "imageGenerator = ImageDataGenerator(\n",
    "    rescale            = 1./255,       # Scale our data to our dataset scale\n",
    "    horizontal_flip    = True,         # Horizontal mirror\n",
    "    vertical_flip      = False,         # Disable vertical mirror\n",
    "    rotation_range     = 7,\n",
    "    width_shift_range  = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    brightness_range   = (0.3, 0.7),\n",
    "    shear_range        = 45.0,\n",
    "    zoom_range         = [0.5, 1.5],\n",
    "    fill_mode          = \"reflect\"\n",
    ")\n",
    "\n",
    "trainGenerator = imageGenerator.flow_from_directory(\n",
    "        directory   = DATESET_TRAINING_PATH,\n",
    "        target_size =  (IMG_H, IMG_W),\n",
    "        batch_size  =  BATCH_SIZE,\n",
    "        class_mode  =  'binary',\n",
    "        classes     =  getOutputClasses())\n",
    "\n",
    "testGenerator= imageGenerator.flow_from_directory(\n",
    "        directory    = DATESET_TESTING_PATH,\n",
    "        target_size  = (IMG_H, IMG_W),\n",
    "        batch_size   = BATCH_SIZE,\n",
    "        class_mode   = 'binary',\n",
    "        classes      = getOutputClasses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_momo': 0, 'momo': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGenerator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save some util data from our foulders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples:  184 positive:  80  negative:  104\n",
      "Total test examples:  40 positive:  17  negative:  23\n",
      "\n",
      "Train Steps per epoch  18\n",
      "Test Steps per epoch  4\n"
     ]
    }
   ],
   "source": [
    "trainPositiveFiles          = getFolderFiles(DATESET_TRAINING_PATH + MOMO_CLASSNAME)\n",
    "trainNegativeFiles          = getFolderFiles(DATESET_TRAINING_PATH + NO_MOMO_CLASSNAME)\n",
    "trainPositiveExamplesLength = len(trainPositiveFiles)\n",
    "trainNegativeExamplesLength = len(trainNegativeFiles)\n",
    "trainLength                 = trainPositiveExamplesLength + trainNegativeExamplesLength\n",
    "\n",
    "print(\"Total train examples: \", trainLength , \"positive: \" , trainPositiveExamplesLength  , \" negative: \" , trainNegativeExamplesLength)\n",
    "\n",
    "testPositiveFiles           = getFolderFiles(DATESET_TESTING_PATH + MOMO_CLASSNAME)\n",
    "testNegativeFiles           = getFolderFiles(DATESET_TESTING_PATH + NO_MOMO_CLASSNAME)\n",
    "testPositiveExamplesLength  = len(testPositiveFiles)\n",
    "testNegativeExamplesLength  = len(testNegativeFiles)\n",
    "testLength                  = testPositiveExamplesLength + testNegativeExamplesLength\n",
    "\n",
    "print(\"Total test examples: \", testLength , \"positive: \" , testPositiveExamplesLength  , \" negative: \" , testNegativeExamplesLength)\n",
    "print()\n",
    "\n",
    "trainSteps = trainLength // BATCH_SIZE\n",
    "testSteps  = testLength // BATCH_SIZE\n",
    "\n",
    "print(\"Train Steps per epoch \" , trainSteps)\n",
    "print(\"Test Steps per epoch \" , testSteps)\n",
    "\n",
    "callbacks   = []\n",
    "\n",
    "resetFolderIfExist(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH)\n",
    "\n",
    "if SAVE_WEIGHTS:\n",
    "    weightsFileName  =  RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-{epoch}.h5'\n",
    "    mc = keras.callbacks.ModelCheckpoint(\n",
    "        weightsFileName,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True\n",
    "    )\n",
    "    callbacks.append( mc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-48a5d6cd2f05>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 13s 742ms/step - loss: 1.0465 - accuracy: 0.6494 - val_loss: 0.6880 - val_accuracy: 0.5750\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 13s 710ms/step - loss: 0.6254 - accuracy: 0.7241 - val_loss: 0.7305 - val_accuracy: 0.4250\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 13s 703ms/step - loss: 0.4842 - accuracy: 0.7874 - val_loss: 0.7186 - val_accuracy: 0.4750\n",
      "Epoch 4/200\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.4846 - accuracy: 0.8110"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-48a5d6cd2f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestSteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "progress = momoModel.fit_generator(\n",
    "        trainGenerator,\n",
    "        steps_per_epoch=trainSteps,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=testGenerator,\n",
    "        validation_steps=testSteps,\n",
    "        callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listamos la información del entrenamiento\n",
    "print(progress.history.keys())\n",
    "\n",
    "momoModel.save_weights( DEFAULT_WEIGHTS_FILE_PATH)\n",
    "\n",
    "# Acc stats\n",
    "plt.plot(progress.history['accuracy'])\n",
    "plt.plot(progress.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Loss stats\n",
    "plt.plot(progress.history['loss'])\n",
    "plt.plot(progress.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Using the momo model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the last weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix()\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using The weights of  first epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-1.h5')\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-2.h5')\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-3.h5')\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-4.h5')\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files,eval_preds,eval_Xs,eval_Ys = getDataForConfusionMatrix(RESULT_FOLDER_WEIGHTS_INCEPTION_V3_PATH + 'weights-5.h5')\n",
    "createConfusionMatrix(eval_Xs, eval_Ys, classes=getOutputClasses(), normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
